{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHA 550 - Diabetes Readmission Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.23.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting missingno\n",
      "  Downloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from missingno) (3.6.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from missingno) (0.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from missingno) (1.23.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from missingno) (1.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn->missingno) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn->missingno) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Installing collected packages: missingno\n",
      "Successfully installed missingno-0.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.23.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (3.6.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (5.11.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.23.3)\n",
      "Requirement already satisfied: six in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.4.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.0.6)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly->catboost) (8.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex\n",
      "  Downloading regex-2023.3.23-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     -------------------------------------- 267.9/267.9 kB 8.1 MB/s eta 0:00:00\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2023.3.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\emman\\AppData\\Local\\Temp\\pip-install-_um2d11i\\sklearn_53130c434ab640c78ab5056a7afeb4fb\\setup.py\", line 10, in <module>\n",
      "          LONG_DESCRIPTION = f.read()\n",
      "        File \"C:\\Users\\emman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "          return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "      UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 7: character maps to <undefined>\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "     -------------------------------------- 226.0/226.0 kB 7.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.23.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (6.15.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (5.9.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (21.3)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (5.3.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (8.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (23.2.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (7.3.5)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (6.2)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (1.6.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel) (1.5.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.31)\n",
      "Requirement already satisfied: stack-data in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (4.11.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->ipykernel) (3.0.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel) (304)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: asttokens in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.8)\n",
      "Requirement already satisfied: executing in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (1.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.4.0)\n",
      "Collecting nbformat\n",
      "  Downloading nbformat-5.8.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.4/77.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (4.11.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (2.16.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nbformat) (4.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=2.6->nbformat) (22.1.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\emman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core->nbformat) (304)\n",
      "Installing collected packages: nbformat\n",
      "  Attempting uninstall: nbformat\n",
      "    Found existing installation: nbformat 5.4.0\n",
      "    Uninstalling nbformat-5.4.0:\n",
      "      Successfully uninstalled nbformat-5.4.0\n",
      "Successfully installed nbformat-5.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install missingno\n",
    "!pip install xgboost\n",
    "!pip install catboost\n",
    "!pip install regex\n",
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install imblearn\n",
    "!pip install lightgbm\n",
    "!pip install ipykernel\n",
    "!pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "import csv \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import missingno as msno\n",
    "import re \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report, make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score, RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer,SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,\\\n",
    "                            precision_score, recall_score, roc_auc_score,\\\n",
    "                             classification_report,  f1_score\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from plotly.offline import iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with Loading the CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/new_diabetic_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights into our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes['readmitted'] .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes['readmitted'] = diabetes['readmitted'].replace([0,1,2],[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes['readmitted'] .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes['readmitted']\n",
    "print(f'Percentage of patient readmitted under 30 days: % {round(y.value_counts(normalize=True)[1]*100,2)} --> ({y.value_counts()[1]} patient)\\nPercentage of patient not readmitted within 30 days: % {round(y.value_counts(normalize=True)[0]*100,2)} --> ({y.value_counts()[0]} patient)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize readmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(diabetes, x=\"readmitted\", title='Readmitted within 30 days', width=400, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing Data / Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing (diabetes):\n",
    "    missing_number = diabetes.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (diabetes.isnull().sum()/diabetes.isnull().count()).sort_values(ascending=False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
    "    return missing_values\n",
    "\n",
    "missing(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(diabetes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.hist(figsize=(20,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix & Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = diabetes.corr()\n",
    "diabetes[diabetes.columns[1:]].corr()['readmitted'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.groupby('readmitted').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Drop the columns that are either missing most of the times or are not relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns which are not required\n",
    "diabetes.drop(['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight',\n",
    "           'payer_code', 'medical_specialty', 'num_lab_procedures', 'num_procedures', \n",
    "           'num_medications', 'time_in_hospital', 'number_outpatient', 'diag_1', 'diag_2', 'diag_3', 'number_emergency', 'number_inpatient', \n",
    "           'number_diagnoses', 'metformin', 'change'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = diabetes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking the data up into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = np.split(diabetes.sample(frac=1, random_state=42), \n",
    "                                       [int(.7*len(diabetes)), int(0.85*len(diabetes))])\n",
    "train_df = train_df.reset_index(drop = True)\n",
    "valid_df = valid_df.reset_index(drop = True)\n",
    "test_df = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating the Imbalance in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):    \n",
    "    return (sum(y_actual)/len(y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pos = train_df.readmitted == 1\n",
    "df_train_pos = train_df.loc[rows_pos]\n",
    "df_train_neg = train_df.loc[~rows_pos]\n",
    "\n",
    "diabetes_df_balanced = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 111)],axis = 0)\n",
    "\n",
    "diabetes_df_balanced = diabetes_df_balanced.sample(n = len(diabetes_df_balanced), random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(diabetes_df_balanced), \\\n",
    "                                                calc_prevalence(diabetes_df_balanced.readmitted.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df_balanced.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = diabetes_df_balanced.drop('readmitted',axis=1)\n",
    "\n",
    "y_train = diabetes_df_balanced['readmitted']\n",
    "\n",
    "X_valid = valid_df.drop('readmitted',axis=1)\n",
    "\n",
    "y_valid = valid_df['readmitted']\n",
    "\n",
    "X_test = test_df.drop('readmitted',axis=1)\n",
    "\n",
    "y_test = test_df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train[['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed']] = pd.DataFrame(scaler.fit_transform(X_train[['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed']]), columns=['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed'])\n",
    "X_valid[['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed']] = pd.DataFrame(scaler.transform(X_valid[['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed']]), columns=['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed'])\n",
    "X_test[['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed']] = pd.DataFrame(scaler.transform(X_test[['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed']]), columns=['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "       'max_glu_serum', 'A1Cresult', 'insulin', 'diabetesMed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Understanding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh = 0.5):\n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr = LinearRegression()\n",
    "lnr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_valid_preds = lnr.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state = 42, solver = 'newton-cg', max_iter = 200)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_valid_preds = lr.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print('Metrics for Validation data:')\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,y_valid_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 100)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_preds = knn.predict_proba(X_valid)[:,1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,knn_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc=SGDClassifier(loss = 'log',alpha = 0.1,random_state = 42)\n",
    "sgdc.fit(X_train, y_train)\n",
    "\n",
    "sgd_preds = sgdc.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print('Stochastic Gradient Descent')\n",
    "print('Validation:')\n",
    "sgdc_valid_auc, sgdc_valid_accuracy, sgdc_valid_recall, \\\n",
    "                sgdc_valid_precision, sgdc_valid_specificity = print_report(y_valid,sgd_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_clf = DecisionTreeClassifier(random_state=42, max_depth = 10)\n",
    "dc_clf.fit(X_train, y_train)\n",
    "\n",
    "dc_preds_proba = dc_clf.predict_proba(X_valid)[:,1]\n",
    "dc_preds = dc_clf.predict(X_valid)\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,dc_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=111, max_depth = 6)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_clf.predict(X_valid)\n",
    "rf_preds_proba = rf_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,rf_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_clf = LinearSVC(random_state=111)\n",
    "lsvc_clf.fit(X_train, y_train)\n",
    "\n",
    "lsvc_preds = lsvc_clf.decision_function(X_valid)\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,lsvc_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators = 100, criterion='friedman_mse', learning_rate = 1.0, max_depth = 3,\\\n",
    "                                    random_state = 111)\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_preds = gb_clf.predict(X_valid)\n",
    "gb_preds_proba = gb_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,gb_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=3, learning_rate = 1.0, use_label_encoder = False,\\\n",
    "                            eval_metric = 'logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = xgb_clf.predict(X_valid)\n",
    "xgb_preds_proba = xgb_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,xgb_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb=CatBoostClassifier(iterations=200, depth=3, learning_rate=1.0, random_state = 111)\n",
    "catb.fit(X_train, y_train)\n",
    "catb_preds = catb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,catb_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scoring = make_scorer(recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_grid = {'max_features':['auto','sqrt'], \n",
    "           'max_depth':range(1,11,1),\n",
    "           'min_samples_split':range(2,10,2), \n",
    "           'criterion':['gini','entropy']} \n",
    "\n",
    "dc_random = RandomizedSearchCV(estimator = dc_clf, param_distributions = dc_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=recall_scoring,\n",
    "                               verbose = 1, random_state = 111)\n",
    "\n",
    "dc_random.fit(X_train, y_train)\n",
    "\n",
    "dc_random.best_params_\n",
    "\n",
    "dc_hp_preds = dc_random.best_estimator_.predict(X_valid)\n",
    "dc_hp_preds_proba = dc_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, dc_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_valid, dc_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = {'n_estimators':range(200,1000,200), \n",
    "           'max_features':['auto','sqrt'], \n",
    "           'max_depth':range(1,11,1), \n",
    "           'min_samples_split':range(2,10,2), \n",
    "           'criterion':['gini','entropy']}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = rf_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=recall_scoring,\n",
    "                               verbose = 1, random_state = 111)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_\n",
    "\n",
    "rf_hp_preds = rf_random.best_estimator_.predict(X_valid)\n",
    "rf_hp_preds_proba = rf_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, rf_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_valid, rf_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = params = {\n",
    "        'min_child_weight': [1, 5, 8, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        } \n",
    "\n",
    "xgb_random = GridSearchCV(estimator = xgb_clf, param_grid = xgb_grid, \n",
    "                               cv = 2, scoring = recall_scoring,\n",
    "                               verbose = 1)\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "xgb_random.best_params_\n",
    "\n",
    "xgb_hp_preds = xgb_random.best_estimator_.predict(X_valid)\n",
    "xgb_hp_preds_proba = xgb_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, xgb_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_valid, xgb_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Model Results and Findings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that this is a tricky dataset and therefore the normal models might not work, we would need to further use hyper-parameter tuning to improve the performance. To learn about hyper-parameter tuning click [here](https://scikit-learn.org/stable/modules/grid_search.html).\n",
    "* Deep Learning techniques can also be used as they can prove to be really effective in such tricky datasets. One can use `CNN(Convolutional Neural Network)` for this or can also try to use `RNN(Recurrent Neural Network)`.\n",
    "\n",
    "In this notebook we have created a binary classifier to predict the probability that a patient with certain condition would get a diabetes or not. On held out test data, our best model had a recall of of 0.83. Using this model, we are able to catch 83% of the patients with diabetes correctly. While building the models we have focussed on making sure that we have the least number of false negatives and therefore we have used recall as the metric. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80acabf83f03f6708b4a7d1d74fe7eb69e19c51052afaa6d4e26b05791fa57cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
