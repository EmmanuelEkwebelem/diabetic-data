{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHA 550 - Diabetes Readmission Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "# !pip install missingno\n",
    "# !pip install xgboost\n",
    "# !pip install catboost\n",
    "# !pip install regex\n",
    "# !pip install sklearn\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install imblearn\n",
    "# !pip install lightgbm\n",
    "# !pip install ipykernel\n",
    "# !pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "import csv \n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline   \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import missingno as msno\n",
    "import re \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, classification_report, make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score, RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer,SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,\\\n",
    "                            precision_score, recall_score, roc_auc_score,\\\n",
    "                            plot_confusion_matrix, classification_report, plot_roc_curve, f1_score\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from plotly.offline import iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with Loading the CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/new_diabetic_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights into our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes['readmitted'] .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes['readmitted'] = diabetes['readmitted'].replace([0,1,2],[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes['readmitted'] .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes['readmitted']\n",
    "print(f'Percentage of patient readmitted under 30 days: % {round(y.value_counts(normalize=True)[1]*100,2)} --> ({y.value_counts()[1]} patient)\\nPercentage of patient not readmitted within 30 days: % {round(y.value_counts(normalize=True)[0]*100,2)} --> ({y.value_counts()[0]} patient)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize readmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(diabetes, x=\"readmitted\", title='Readmitted within 30 days', width=400, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Missing Data / Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing (diabetes):\n",
    "    missing_number = diabetes.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (diabetes.isnull().sum()/diabetes.isnull().count()).sort_values(ascending=False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
    "    return missing_values\n",
    "\n",
    "missing(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(diabetes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.hist(figsize=(20,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix & Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = diabetes.corr()\n",
    "diabetes[diabetes.columns[1:]].corr()['readmitted'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.groupby('readmitted').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Drop the columns that are either missing most of the times or are not relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns which are not required\n",
    "diabetes.drop(['encounter_id', 'patient_nbr', 'race', 'gender', 'age', \n",
    "           'payer_code', 'medical_specialty', 'num_lab_procedures', 'num_procedures', \n",
    "           'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', \n",
    "           'number_diagnoses', 'metformin', 'change'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['admission_type_id','discharge_disposition_id','admission_source_id']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking the data up into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = np.split(diabetes.sample(frac=1, random_state=42), \n",
    "                                       [int(.7*len(diabetes)), int(0.85*len(diabetes))])\n",
    "train_df = train_df.reset_index(drop = True)\n",
    "valid_df = valid_df.reset_index(drop = True)\n",
    "test_df = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating the Imbalance in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):    \n",
    "    return (sum(y_actual)/len(y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pos = train_df.readmitted == 1\n",
    "df_train_pos = train_df.loc[rows_pos]\n",
    "df_train_neg = train_df.loc[~rows_pos]\n",
    "\n",
    "diabetes_df_balanced = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 111)],axis = 0)\n",
    "\n",
    "diabetes_df_balanced = diabetes_df_balanced.sample(n = len(diabetes_df_balanced), random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print('Train balanced prevalence(n = %d):%.3f'%(len(diabetes_df_balanced), \\\n",
    "                                                calc_prevalence(diabetes_df_balanced.readmitted.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df_balanced.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = diabetes_df_balanced.drop('readmitted',axis=1)\n",
    "\n",
    "y_train = diabetes_df_balanced['readmitted']\n",
    "\n",
    "X_valid = valid_df.drop('readmitted',axis=1)\n",
    "\n",
    "y_valid = valid_df['readmitted']\n",
    "\n",
    "X_test = test_df.drop('readmitted',axis=1)\n",
    "\n",
    "y_test = test_df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train[['admission_type_id','discharge_disposition_id','admission_source_id']] = pd.DataFrame(scaler.fit_transform(X_train[['admission_type_id','discharge_disposition_id','admission_source_id']]),columns=['admission_type_id','discharge_disposition_id','admission_source_id'])\n",
    "X_valid[['admission_type_id','discharge_disposition_id','admission_source_id']] = pd.DataFrame(scaler.transform(X_valid[['admission_type_id','discharge_disposition_id','admission_source_id']]),columns=['admission_type_id','discharge_disposition_id','admission_source_id'])\n",
    "X_test[['admission_type_id','discharge_disposition_id','admission_source_id']] = pd.DataFrame(scaler.transform(X_test[['admission_type_id','discharge_disposition_id','admission_source_id']]),columns=['admission_type_id','discharge_disposition_id','admission_source_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Understanding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh = 0.5):\n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr = LinearRegression()\n",
    "lnr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_valid_preds = lnr.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(random_state = 42, solver = 'newton-cg', max_iter = 200)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_valid_preds = lr.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print('Metrics for Validation data:')\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,y_valid_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 100)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn_preds = knn.predict_proba(X_valid)[:,1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,knn_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc=SGDClassifier(loss = 'log',alpha = 0.1,random_state = 42)\n",
    "sgdc.fit(X_train, y_train)\n",
    "\n",
    "sgd_preds = sgdc.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print('Stochastic Gradient Descent')\n",
    "print('Validation:')\n",
    "sgdc_valid_auc, sgdc_valid_accuracy, sgdc_valid_recall, \\\n",
    "                sgdc_valid_precision, sgdc_valid_specificity = print_report(y_valid,sgd_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_clf = DecisionTreeClassifier(random_state=42, max_depth = 10)\n",
    "dc_clf.fit(X_train, y_train)\n",
    "\n",
    "dc_preds_proba = dc_clf.predict_proba(X_valid)[:,1]\n",
    "dc_preds = dc_clf.predict(X_valid)\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,dc_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=111, max_depth = 6)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_clf.predict(X_valid)\n",
    "rf_preds_proba = rf_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,rf_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_clf = LinearSVC(random_state=111)\n",
    "lsvc_clf.fit(X_train, y_train)\n",
    "\n",
    "lsvc_preds = lsvc_clf.decision_function(X_valid)\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,lsvc_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators = 100, criterion='friedman_mse', learning_rate = 1.0, max_depth = 3,\\\n",
    "                                    random_state = 111)\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_preds = gb_clf.predict(X_valid)\n",
    "gb_preds_proba = gb_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,gb_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=3, learning_rate = 1.0, use_label_encoder = False,\\\n",
    "                            eval_metric = 'logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = xgb_clf.predict(X_valid)\n",
    "xgb_preds_proba = xgb_clf.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,xgb_preds_proba, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb=CatBoostClassifier(iterations=200, depth=3, learning_rate=1.0, random_state = 111)\n",
    "catb.fit(X_train, y_train)\n",
    "catb_preds = catb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity = print_report(y_valid,catb_preds, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scoring = make_scorer(recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_grid = {'max_features':['auto','sqrt'], \n",
    "           'max_depth':range(1,11,1),\n",
    "           'min_samples_split':range(2,10,2), \n",
    "           'criterion':['gini','entropy']} \n",
    "\n",
    "dc_random = RandomizedSearchCV(estimator = dc_clf, param_distributions = dc_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=recall_scoring,\n",
    "                               verbose = 1, random_state = 111)\n",
    "\n",
    "dc_random.fit(X_train, y_train)\n",
    "\n",
    "dc_random.best_params_\n",
    "\n",
    "dc_hp_preds = dc_random.best_estimator_.predict(X_valid)\n",
    "dc_hp_preds_proba = dc_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, dc_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_valid, dc_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = {'n_estimators':range(200,1000,200), \n",
    "           'max_features':['auto','sqrt'], \n",
    "           'max_depth':range(1,11,1), \n",
    "           'min_samples_split':range(2,10,2), \n",
    "           'criterion':['gini','entropy']}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = rf_grid, \n",
    "                               n_iter = 20, cv = 2, scoring=recall_scoring,\n",
    "                               verbose = 1, random_state = 111)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_\n",
    "\n",
    "rf_hp_preds = rf_random.best_estimator_.predict(X_valid)\n",
    "rf_hp_preds_proba = rf_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, rf_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_valid, rf_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = params = {\n",
    "        'min_child_weight': [1, 5, 8, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        } \n",
    "\n",
    "xgb_random = GridSearchCV(estimator = xgb_clf, param_grid = xgb_grid, \n",
    "                               cv = 2, scoring = recall_scoring,\n",
    "                               verbose = 1)\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "xgb_random.best_params_\n",
    "\n",
    "xgb_hp_preds = xgb_random.best_estimator_.predict(X_valid)\n",
    "xgb_hp_preds_proba = xgb_random.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "roc_auc_score(y_valid, xgb_hp_preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_valid, xgb_hp_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Model Results and Findings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that this is a tricky dataset and therefore the normal models might not work, we would need to further use hyper-parameter tuning to improve the performance. To learn about hyper-parameter tuning click [here](https://scikit-learn.org/stable/modules/grid_search.html).\n",
    "* Deep Learning techniques can also be used as they can prove to be really effective in such tricky datasets. One can use `CNN(Convolutional Neural Network)` for this or can also try to use `RNN(Recurrent Neural Network)`.\n",
    "\n",
    "In this notebook we have created a binary classifier to predict the probability that a patient with certain condition would get a diabetes or not. On held out test data, our best model had a recall of of 0.83. Using this model, we are able to catch 83% of the patients with diabetes correctly. While building the models we have focussed on making sure that we have the least number of false negatives and therefore we have used recall as the metric. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80acabf83f03f6708b4a7d1d74fe7eb69e19c51052afaa6d4e26b05791fa57cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
